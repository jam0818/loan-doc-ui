# LLMとPlaywrightで実現する「ちょうどいい」E2Eテスト自動化の落としどころ

## はじめに

E2Eテストの自動化は、メンテナンスコストとの戦いです。
「全部AIに任せればいい」と思いがちですが、実際にはコンテキストの限界やUIの微妙な変化による誤検知など、完全自動化には高い壁があります。

本プロジェクトでの試行錯誤を経てたどり着いた、「LLMの強み」と「人間の操作」を組み合わせた**実用的で持続可能なE2Eテスト作成フロー**についてまとめます。

## 課題：AIによる「完全自動化」の壁

当初は「テストコードの作成も、画面操作の特定も、全部AIにやらせよう」としていました。
しかし、以下の問題に直面しました。

1. **コンテキストの爆発**: UIの構造（DOM）や状態管理のロジックをすべてLLMに理解させるには、膨大なトークンが必要です。
2. **微細な操作のズレ**: 「ボタンを押す」という単純な操作でも、アニメーション待ちや要素の重なり、disabled状態の判定など、AIが推論だけで完璧な待機処理を書くのは困難です。
3. **メンテ不能な巨大コード**: 自動生成された巨大なテストコードは、人間が読み解くのが難しく、ちょっとしたUI変更で壊れやすくなります。

## 解決策：「ちょうどいい」役割分担

そこでの結論は、**「網羅性の担保」と「基盤作り」はAI**に、**「実際の操作」はPlaywright Codegen**に任せる、というハイブリッドなアプローチです。

最終的な最強フローは以下の通りです。

### 1. FEコードから網羅的なテストケースをLLMで作成

まず、ソースコード（Vueコンポーネントなど）をLLMに分析させ、機能・異常系・境界値を網羅した**テストシナリオチェックリスト**を作成します。
人間が考える「漏れ」をAIがカバーし、60ケース以上の詳細なリストが一瞬で完成しました。

### 2. 共通基盤（Reporter / Helper）と「スケルトン」の整備

次に、テストの実行結果を集計したり、共通操作を簡単にするための基盤を整備します。

- **Custom Reporter**: テスト結果と前後のスクリーンショットをExcelにまとめる仕組み。
- **captureStep Helper**: 「操作 → 待機 → スクショ」の定型処理を1行で書けるラッパー関数。
- **Scenario Skeletons**: チェックリストに基づいた、中身が空っぽのテストファイル（スケルトン）を大量生成。

ここまではLLMが非常に得意な領域です。「このチェックリストに対応するPlaywrightのテストファイルの枠組みを作って」と頼めば、一瞬で63ファイル分のスケルトンが生成されました。

### 3. Playwright Codegen で「実際の操作」を注入

ここが肝です。AIに無理にlocatorを書かせるのではなく、**人間がブラウザを操作して、Playwright Codegenにコードを書かせます**。

```bash
npx playwright codegen http://localhost:3000
```

生成されたコード（`await page.getByRole(...).click()` など）を、AIが作ったスケルトンの `captureStep` の中にコピペします。

```typescript
test('AUTH-01: ログイン成功', async ({ page }) => {
    // スケルトン（AI生成）
    const { beforePath, afterPath } = await captureStep(page, 'AUTH-01', 'login', async () => {
        
        // === ここにCodegenのコードをコピペ ===
        await page.getByLabel('ユーザー名').fill('user1')
        await page.getByLabel('パスワード').fill('password')
        await page.getByRole('button', { name: 'ログイン' }).click()
        // ===================================
        
    })
    // ...
})
```

これにより、「正確で壊れにくいセレクタ」と「構造化されたテスト管理」の両立が実現しました。

### 4. 自動テスト実行とExcelレポート

あとはCIやローカルでテストを回すだけ。
`addResult` などを組み込んだスケルトンのおかげで、テストが終わると**スクリーンショット付きのExcelレポート**が自動生成されます。誰でも結果を確認できる状態になります。

## まとめ

「すべてを自動化する」のではなく、「人間が操作した方が早い・正確な部分」と「AIが得意な構造化・網羅性」を組み合わせるのが、現状のE2Eテスト自動化の最適解（落としどころ）だと感じました。

1. **AI**: コードを読んで全シナリオを洗い出す
2. **AI**: テストのハコ（スケルトン）と便利ツールを作る
3. **人間**: Codegenで直感的に操作を記録する
4. **AI/CI**: 実行してレポートにまとめる

このフローであれば、コンテキスト制限に悩まされることなく、堅牢で網羅的なテストスイートを効率的に構築できます。
